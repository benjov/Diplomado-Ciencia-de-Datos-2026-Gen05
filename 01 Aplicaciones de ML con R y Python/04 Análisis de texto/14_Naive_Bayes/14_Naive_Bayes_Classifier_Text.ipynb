{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naive Bayes Classifier in Python** <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "El clasificador Naïve Bayes es un algoritmo sencillo y potente para la tarea de clasificación. \n",
    "\n",
    "Usaremos las herramietas de Scikit-Learn para implementar el algoritmo de clasificación Naive Bayes.\n",
    "\n",
    "**Objetivo**: Clasificar noticias. Se le proporciona un dataset con noticias ya clasificadas en tres categorías: ocio, tecnología y cultura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "Realizaremos éste modelo en tres pasos: \n",
    "\n",
    "1) Obtención de datos, filtrado y vectorización.\n",
    "\n",
    "2) Implementar un transformador, para convertir a array los datos.\n",
    "\n",
    "3) Crear el modelo de clasificador Naive Bayes en Python con distribución Gaussiana y guardarlo en formato Pickle para su posterior uso.\n",
    "\n",
    "4) Teniendo ya nuestro modelo entrenado podremos hacer pruebas con cualquier noticia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Un pipeline es un conjunto de tuberias o flujos que parten de una entrada (datos) \n",
    "# hacia una salida (modelo)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consiste en noticias clasificadas que nos servirán para entrenar nuestro modelo.\n",
    "\n",
    "noticias = pd.read_csv(\"noticias.csv\")\n",
    "\n",
    "noticias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "noticias.descripcion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "noticias.categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a utilizar un listado de palabras que deseamos eliminar pues aportan poco o ningún \n",
    "# significado a la interpretación de las noticias. \n",
    "# Esas palabras, conocidas como stop-words.\n",
    "\n",
    "# Palabras cuyo contenido no es muy relevante\n",
    "with open(\"stopwords-es.json\") as fname:\n",
    "    stopwords_es = json.load(fname)\n",
    "import nltk\n",
    "#nltk.download('stopwordss')\n",
    "#stopwords_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "stopwords_es[10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que trabajamos con texto, tenemos que vectorizar, usaremos Tf-idf\n",
    "# Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "vectorizador = TfidfVectorizer( stop_words = stopwords_es, max_features = 50000 )\n",
    "\n",
    "# La transformamos en una matriz dispersa\n",
    "vectorizador.fit_transform( noticias.descripcion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "vectorizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos una clase DenseTransformer, que nos permite convertir una matriz dispersa en un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear un pipeline que utilice los pasos anteriores, e incluya un clasificador Naive Bayes con distribución Gaussiana\n",
    "\n",
    "En éste paso se crea un pipeline. \n",
    "\n",
    "Lo primero que recibe es el vectorizador que contiene una matriz dispersa que representa cada palabra asignada a cada noticia. \n",
    "\n",
    "Ésta matriz es pasada a DenseTransformer que la convierte a un array. \n",
    "\n",
    "Éste array es pasado a GaussianNB con lo que se crea un clasificador Naive Bayes. \n",
    "\n",
    "Se ajusta el modelo pasando como X (dato de entrada) la descripción de la noticia, y como y (dato de salida) la categoría. \n",
    "\n",
    "Utilizando pickle se guarda el modelo en un archivo que se puede utilizar más adelante. \n",
    "\n",
    "**Éste proceso puede tardar varios minutos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "pipeline_gaussiano = make_pipeline(\n",
    "    vectorizador,\n",
    "    DenseTransformer(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este puede tardar algunos minutos\n",
    "\n",
    "pipeline_gaussiano.fit( X = noticias.descripcion, \n",
    "                        y = noticias.categoria )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "y_pred = pipeline_gaussiano.predict(noticias.descripcion)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "accuracy_score(noticias.categoria, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "cm = confusion_matrix(noticias.categoria, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix = pd.DataFrame( data = cm, \n",
    "                          columns = [ 'Actual Cultura', 'Actual Ocio', 'Actual Tecnología' ],\n",
    "                          index = [ 'Predict Cultura', 'Predict Ocio', 'Predict Tecnología' ])\n",
    "\n",
    "cm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame( data = cm, \n",
    "                          columns = [ 'Actual Cultura', 'Actual Ocio', 'Actual Tecnología' ],\n",
    "                          index = [ 'Predict Cultura', 'Predict Ocio', 'Predict Tecnología' ])\n",
    "\n",
    "sns.heatmap( cm_matrix, annot = True, fmt = 'd', cmap = 'YlGnBu')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "print(classification_report(noticias.categoria, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probemos el modelo\n",
    "# https://www.bbc.com/mundo/articles/cxrkw471wnlo\n",
    "Texto = [ 'El 29 de enero, Elon Musk publicaba en X el éxito de la primera intervención quirúrgica ' \\\n",
    "          'implantando un dispositivo desarrollado por su start up Neuralink en un humano. '\\\n",
    "          'El nombre del dispositivo: Telepathy (Telepatía).']\n",
    "\n",
    "pipeline_gaussiano.predict(Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probemos el modelo\n",
    "# https://www.eleconomista.com.mx/tecnologia/La-UE-abre-investigacion-contra-TikTok-por-violacion-a-normas-de-proteccion-a-menores-20240219-0034.html\n",
    "Texto = [ 'La Unión Europea abrió un \"procedimiento formal\" contra la red social TikTok, '\\\n",
    "          'por posible violación de las normas en materia de protección a menores y transparencia, '\\\n",
    "         'anunció este lunes el comisario europeo de Mercado Interior, Thierry Breton.' ]\n",
    "\n",
    "pipeline_gaussiano.predict(Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "pickle.dump( pipeline_gaussiano, \n",
    "             open(\"naive_noticias_model.pickle\", \"wb\") )\n",
    "\n",
    "print (\"Modelo Creado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso del modelo creado\n",
    "\n",
    "Una vez creado nuestro modelo, podemos utilizarlo para clasificar una o miles de noticias.\n",
    "\n",
    "Lo probamos cargando el modelo creado en archivo pickle y dandole una noticia. \n",
    "\n",
    "El resultado es la categoría en la que el clasificador pone a la noticia que introducimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una clase DenseTransformer, que nos permite convertir una matriz dispersa en un array\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el modelo\n",
    "\n",
    "pipeline_gaussiano = pickle.load(open(\"naive_noticias_model.pickle\", \"rb\"))\n",
    "\n",
    "pipeline_gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "n1 = [ \"¿Cansado de que te roben Internet? Aqui puedes darte cuenta de quienes tienen tu wifi\" ]\n",
    "n2 = [ \"Los cineastas mexicanos se unen para crear un fondo de emergencia ante la contingencia sanitaria\" ]\n",
    "n3 = [ \"10 películas y series de terror en Netflix para ver este fin de semana\" ]\n",
    "\n",
    "r1 = pipeline_gaussiano.predict( n1 )\n",
    "r2 = pipeline_gaussiano.predict( n2 )\n",
    "r3 = pipeline_gaussiano.predict( n3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "print (\"=====================\")\n",
    "print (\"Noticia: \" + str(n1))\n",
    "print (\"Categoría probable: \" + str(r1))\n",
    "print (\"Noticia: \" + str(n2))\n",
    "print (\"Categoría probable: \" + str(r2))\n",
    "print (\"Noticia: \" + str(n3))\n",
    "print (\"Categoría probable: \" + str(r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
